method,rows,image size mb,peak memory mb,total time min,type,postgres only,Handles rotating credentials?,platform,finished,notes
pg_dump/pg_restore,"41,011,955.00",145,34,3,EL,TRUE,TRUE,postgresql,TRUE,
pyspark_write,"41,011,955.00",1610,1075,4.5,ETL,FALSE,TRUE,python,TRUE,
spark_write,"41,011,955.00",1330,2053,5,ETL,FALSE,TRUE,scala,TRUE,
polars_connectorx_copy,"41,011,955.00",943,11330,5,ETL,TRUE,TRUE,python,TRUE,
polars adbc copy,"41,011,955.00",841,11320,6,ETL,TRUE,TRUE,python,TRUE,
pg_dump/pg_restore,"2,000,000.00",145,20,0.05,EL,TRUE,TRUE,postgresql,TRUE,This is purely EL job.  It needs a pgpass file that might be a hassle to manage. You can't specify the name of the target table in an easy way (Has to be the same than the original)
polars adbc copy,"2,000,000.00",841,587,0.05,ETL,TRUE,TRUE,python,TRUE,
polars_connectorx_copy,"2,000,000.00",943,600,0.05,ETL,TRUE,TRUE,python,TRUE,
pyspark_write,"2,000,000.00",1610,960,0.25,ETL,FALSE,TRUE,python,TRUE,
spark_write,"2,000,000.00",1330,1775,0.5,ETL,FALSE,TRUE,scala,TRUE,
pandas read_sql_copy,"2,000,000.00",693,400,1,ETL,TRUE,TRUE,python,TRUE,
polars_connectorx_write,"2,000,000.00",1140,1867,1.5,ETL,TRUE,TRUE,python,TRUE,
pandas read_sql_to_sql,"2,000,000.00",693,7700,5,ETL,FALSE,TRUE,python,TRUE,
polars_connectorx_write,"41,011,955.00",1140,13450,,ETL,TRUE,TRUE,python,FALSE,ran out of memory. 16 GB machine.
pandas read_sql_copy,"41,011,955.00",693,13960,,ETL,TRUE,TRUE,python,FALSE,ran out of memory. 16 GB machine.
pandas read_sql_to_sql,"41,011,955.00",693,10000,,ETL,TRUE,TRUE,python,FALSE,ran out of memory. 16 GB machine.
